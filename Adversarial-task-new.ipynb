{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb22ba0d9e74f51b855ac3c14666672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on int64 and object columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-20d20b7f887e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#Those attributes will be required for the final part of the assignment (applying smiles)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlfw_dataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_lfw_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_lfw_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdimx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m36\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdimy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m36\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#preprocess faces\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PBL\\lfw_dataset.py\u001b[0m in \u001b[0;36mload_lfw_dataset\u001b[1;34m(use_raw, dx, dy, dimx, dimy)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;31m# preserve photo_ids order!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mall_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mphoto_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_attrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'person'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'imagenum'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"person\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"imagenum\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mall_photos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_attrs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m   6377\u001b[0m                      \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6378\u001b[0m                      \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6379\u001b[1;33m                      copy=copy, indicator=indicator, validate=validate)\n\u001b[0m\u001b[0;32m   6380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6381\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     58\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                          validate=validate)\n\u001b[0m\u001b[0;32m     61\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[1;31m# to avoid incompat dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[1;31m# If argument passed to validate,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;31m# incompatible dtypes GH 9780, GH 15800\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mis_numeric_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_numeric_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    979\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_numeric_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_numeric_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on int64 and object columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "plt.rcParams.update({'axes.titlesize': 'small'})\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "#The following line fetches two datasets: images, usable for autoencoder training and attributes.\n",
    "#Those attributes will be required for the final part of the assignment (applying smiles)\n",
    "from lfw_dataset import load_lfw_dataset \n",
    "data,attrs = load_lfw_dataset(dimx=36,dimy=36)\n",
    "\n",
    "#preprocess faces\n",
    "data = np.float32(data)/255.\n",
    "\n",
    "IMG_SHAPE = data.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print random image\n",
    "plt.imshow(data[np.random.randint(data.shape[0])], cmap=\"gray\", interpolation=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(allow_growth=True,per_process_gpu_memory_fraction=0.333)\n",
    "s = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import layers as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CODE_SIZE = 256\n",
    "\n",
    "generator = Sequential()\n",
    "generator.add(L.InputLayer([CODE_SIZE],name='noise'))\n",
    "generator.add(L.Dense(10*8*8, activation='elu'))\n",
    "\n",
    "generator.add(L.Reshape((8,8,10)))\n",
    "generator.add(L.Deconv2D(64,kernel_size=(5,5),activation='elu'))\n",
    "generator.add(L.Deconv2D(64,kernel_size=(5,5),activation='elu'))\n",
    "generator.add(L.UpSampling2D(size=(2,2)))\n",
    "generator.add(L.Deconv2D(32,kernel_size=3,activation='elu'))\n",
    "generator.add(L.Deconv2D(32,kernel_size=3,activation='elu'))\n",
    "generator.add(L.Deconv2D(32,kernel_size=3,activation='elu'))\n",
    "\n",
    "generator.add(L.Conv2D(3,kernel_size=3,activation=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert generator.output_shape[1:] == IMG_SHAPE, \"generator must output an image of shape %s, but instead it produces %s\"%(IMG_SHAPE,generator.output_shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "* Discriminator is usual convolutional network with interlooping convolution and pooling layers\n",
    "* The network does not include dropout/batchnorm to avoid learning complications.\n",
    "* We also regularize the pre-output layer to prevent discriminator from being too certain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Sequential()\n",
    "\n",
    "discriminator.add(L.InputLayer(IMG_SHAPE))\n",
    "\n",
    "discriminator.add(L.Conv2D(8, (3, 3)))\n",
    "discriminator.add(L.LeakyReLU(0.1))\n",
    "discriminator.add(L.Conv2D(16, (3, 3)))\n",
    "discriminator.add(L.LeakyReLU(0.1))\n",
    "discriminator.add(L.MaxPool2D())\n",
    "discriminator.add(L.Conv2D(32, (3, 3)))\n",
    "discriminator.add(L.LeakyReLU(0.1))\n",
    "discriminator.add(L.Conv2D(64, (3, 3)))\n",
    "discriminator.add(L.LeakyReLU(0.1))\n",
    "discriminator.add(L.MaxPool2D())\n",
    "\n",
    "discriminator.add(L.Flatten())\n",
    "discriminator.add(L.Dense(256,activation='tanh'))\n",
    "discriminator.add(L.Dense(2,activation=tf.nn.log_softmax))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.placeholder('float32',[None,CODE_SIZE])\n",
    "real_data = tf.placeholder('float32',[None,]+list(IMG_SHAPE))\n",
    "\n",
    "logp_real = discriminator(real_data)\n",
    "\n",
    "generated_data =generator(noise)\n",
    "\n",
    "logp_gen = discriminator(generated_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "#discriminator training#\n",
    "########################\n",
    "\n",
    "d_loss = -tf.reduce_mean(logp_real[:,1] + logp_gen[:,0])\n",
    "\n",
    "#regularize\n",
    "d_loss += tf.reduce_mean(discriminator.layers[-1].kernel**2)\n",
    "\n",
    "#optimize\n",
    "disc_optimizer =  tf.train.GradientDescentOptimizer(1e-3).minimize(d_loss,var_list=discriminator.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "###generator training###\n",
    "########################\n",
    "\n",
    "g_loss =-tf.reduce_mean(logp_gen[:,1])\n",
    "\n",
    "gen_optimizer = tf.train.AdamOptimizer(1e-4).minimize(g_loss,var_list=generator.trainable_weights)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions\n",
    "Here we define a few helper functions that draw current data distributions and sample training batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_noise_batch(bsize):\n",
    "    return np.random.normal(size=(bsize, CODE_SIZE)).astype('float32')\n",
    "\n",
    "def sample_data_batch(bsize):\n",
    "    idxs = np.random.choice(np.arange(data.shape[0]), size=bsize)\n",
    "    return data[idxs]\n",
    "\n",
    "def sample_images(nrow,ncol, sharp=False):\n",
    "    images = generator.predict(sample_noise_batch(bsize=nrow*ncol))\n",
    "    if np.var(images)!=0:\n",
    "        images = images.clip(np.min(data),np.max(data))\n",
    "    for i in range(nrow*ncol):\n",
    "        plt.subplot(nrow,ncol,i+1)\n",
    "        if sharp:\n",
    "            plt.imshow(images[i].reshape(IMG_SHAPE),cmap=\"gray\", interpolation=\"none\")\n",
    "        else:\n",
    "            plt.imshow(images[i].reshape(IMG_SHAPE),cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "def sample_probas(bsize):\n",
    "    plt.title('Generated vs real data')\n",
    "    plt.hist(np.exp(discriminator.predict(sample_data_batch(bsize)))[:,1],\n",
    "             label='D(x)', alpha=0.5,range=[0,1])\n",
    "    plt.hist(np.exp(discriminator.predict(generator.predict(sample_noise_batch(bsize))))[:,1],\n",
    "             label='D(G(z))',alpha=0.5,range=[0,1])\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Main loop.\n",
    "We just train generator and discriminator in a loop and plot results once every N iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "        from IPython import display\n",
    "from tqdm import tnrange\n",
    "\n",
    "for epoch in tnrange(50000):\n",
    "    \n",
    "    feed_dict = {\n",
    "        real_data:sample_data_batch(100),\n",
    "        noise:sample_noise_batch(100)\n",
    "    }\n",
    "    \n",
    "    for i in range(5):\n",
    "        s.run(disc_optimizer,feed_dict)\n",
    "    \n",
    "    s.run(gen_optimizer,feed_dict)\n",
    "    \n",
    "    if epoch %100==0:\n",
    "        display.clear_output(wait=True)\n",
    "        sample_images(2,3,True)\n",
    "        sample_probas(1000)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#The network was trained for about 15k iterations. \n",
    "#Training for longer yields MUCH better results\n",
    "plt.figure(figsize=[16,24])\n",
    "sample_images(16,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
